# <span style="color:#C0BFEC">Языки прикладного программирования</span>
Лабораторная работа №3 “Кластеризация”

## <span style="color:#C0BFEC">Задание на лабораторную работу:
## <span style="color:#C0BFEC">Кластерный анализ:
Кластеризация (англ. cluster analysis) — задача группировки множества объектов на подмножества (кластеры) таким образом, чтобы объекты из одного кластера были более похожи друг на друга, чем на объекты из других кластеров по какому-либо критерию. 
Задача кластеризации очень часто применяется для первичного анализа статистических данных с целью понять существуют в них группы, объединенные общими критериями. После чего можно уже проводить дальнейшие исследования по формализации этих самых групп и введению классов, что приводит уже к задаче классификации.
Пример кластеризации:

Больше про кластерный анализ можно почитать здесь: https://ru.wikipedia.org/wiki/Кластерный_анализ.

## <span style="color:#C0BFEC">Методы кластеризации:
Самыми распространенными методами кластеризации являются:
1) KMeans (англ. k-means) — самый простой алгоритм кластеризации. Его основная идея - найти центры кластеров (центроиды) и минимизировать суммарное квадратичное отклонение точек кластеров от центров этих кластеров. Центроиды в данном алгоритме по сути выполняют роль центров масс для остальных точек из кластера. Подробно алгоритм расписан здесь.
2) Иерархическая кластеризация — строит иерархию кластеров. Этот алгоритм начинает работу с того, что каждому экземпляру данных сопоставляется свой собственный кластер. Затем два ближайших кластера объединяются в один и так далее, пока не будет образован один общий кластер. Результат иерархической кластеризации может быть представлен с помощью дендрограммы. Иерархическая кластеризация хуже подходит для кластеризации больших объемов данных в сравнении с методом k-средних. Это объясняется тем, что временная сложность алгоритма линейна для метода k-средних (O(n)) и квадратична для метода иерархической кластеризации (O(n2)). Кроме того в кластеризации при помощи метода k-средних алгоритм начинает построение с произвольного выбора начальных точек, поэтому, результаты, генерируемые при многократном запуске алгоритма, могут отличаться. В то же время в случае иерархической кластеризации результаты воспроизводимы. Из центроидной геометрии построения метода k-средних следует, что метод хорошо работает, когда форма кластеров является гиперсферической (например, круг в 2D или сфера в 3D). Но метод k-средних более чувствителен к зашумленным данным, чем иерархический метод.
3) Распространения близости (англ. Affinity Propagation) создает кластеры, отправляя сообщения между парами образцов до схождения. Затем набор данных описывается с использованием небольшого количества образцов, которые определяются как наиболее репрезентативные для других образцов. Сообщения, отправляемые между парами, представляют пригодность одного образца быть образцом другого, который обновляется в ответ на значения из других пар. Это обновление происходит итеративно до сходимости, после чего выбираются окончательные образцы и, следовательно, дается окончательная кластеризация.
4) Средний сдвиг или сдвиг среднего значения (англ. MeanShift) - кластеризация направленная ​​на обнаружение капель в образцах с плавной плотностью. Это алгоритм на основе центроидов, который работает, обновляя кандидатов в центроиды, чтобы они были средними точками в данном регионе. Затем эти кандидаты фильтруются на этапе постобработки, чтобы исключить почти дубликаты и сформировать окончательный набор центроидов. Алгоритм автоматически устанавливает количество кластеров, вместо того, чтобы полагаться на параметр bandwidth, который определяет размер области для поиска. Этот параметр можно установить вручную, но можно оценить с помощью предоставленной estimate_bandwidth функции, которая вызывается, если полоса пропускания не задана. Алгоритм не отличается высокой масштабируемостью, так как он требует многократного поиска ближайшего соседа во время выполнения алгоритма. Алгоритм гарантированно сходится, однако алгоритм прекратит итерацию, когда изменение центроидов будет небольшим.
5) DBSCAN (Density-Based Spatial Clustering of Applications with Noise, плотностной алгоритм пространственной кластеризации с присутствием шума) – популярный алгоритм кластеризации, используемый в анализе данных в качестве одной из замен метода k-средних. Метод не требует предварительных предположений о числе кластеров, но нужно настроить два других параметра: eps и min_samples. Данные параметры – это соответственно максимальное расстояние между соседними точками и минимальное число точек в окрестности (количество соседей), когда можно говорить, что эти экземпляры данных образуют один кластер. В scikit-learn есть соответствующие значения параметров по умолчанию, но, как правило, их приходится настраивать самостоятельно. Подробнее об алгоритме здесь в этой статье.

## <span style="color:#C0BFEC">Задание на лабораторную работу:
Написать программу на языке Python 3, выполняющую кластеризацию входной двумерной выборки на 15 кластеров несколькими методами. 
Результатом каждой кластеризации должна быть картинка графика.

### <span style="color:#C0BFEC">Файл с входной выборкой: 
```
http://cs.joensuu.fi/sipu/datasets/s1.txt
```

Выполнять кластеризацию необходимо с помощью модуля scikit-learn, а строить графики с помощью matplotlib или seaborn.


## <span style="color:#C0BFEC">Методы кластеризации, которыми необходимо воспользоваться в программе:
* KMeans 
* AffinityPropagation
* MeanShift 
* AgglomerativeClustering
* DBSCAN

Сравнить получившиеся результаты кластеризации и сделать выводы о применимости методов к различным видам кластерных данных. Также необходимо уметь отвечать на вопросы о преимуществах и недостатках каждого рассмотренного метода.

## <span style="color:#C0BFEC">Общие требования:
1) На каждом графике должна быть “легенда” 
2) Следовать принципам KISS, DRY, YAGNI и т.п.
3) Код должен соответствовать code-style соответствующего языка: для Python
